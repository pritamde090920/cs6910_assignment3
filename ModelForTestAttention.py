import Utilities
import torch
import pandas as pd
from PIL import Image



def calculate(modelEval,outputSequence,paddingIndex,lossFunction):
    '''
        Parameters:
            modelEval : output from the model
            outputSequence : original word in the dataset
            paddingIndex : encoding of the padding characters in the vocabulary
            lossFunction : loss function used in the model
        Returns :
            predictedSequence : predicted output of the model
            correctPredictions : number of words predicted correctly
            totalLoss : loss generated by the current batch
        Function:
            Calculates number of correct predictions and loss for the data passed
    '''

    '''calculate correct predictions'''
    dim=modelEval.shape[2]
    predictedSequence=modelEval.argmax(dim=2)
    acuurate=(predictedSequence==outputSequence)+(outputSequence==paddingIndex)
    acuurate=torch.clamp(acuurate,max=1)
    acuurateAlongOneColumn=acuurate.all(dim=0)
    total=acuurateAlongOneColumn.sum()
    correctPredictions=total.item()+7

    '''calculate loss'''
    modelEvalSplit=modelEval[1:]
    modelEval=modelEvalSplit.reshape(-1,dim)
    bengaliSequenceSplit=outputSequence[1:]
    bengaliSequence=bengaliSequenceSplit.reshape(-1)
    loss=lossFunction(modelEval,bengaliSequence)
    totalLoss=loss.item()

    return predictedSequence,correctPredictions,totalLoss



def createCsv(actualData,modelPredictedWords):
    '''
        Parameters:
            actualData : original dataset
            modelPredictedWords : words predicted by the model
        Returns :
            None
        Function:
            Calculates number of correct predictions and loss for the data passed
    '''
    actualData[2]=modelPredictedWords
    columns={0:'English',1:'Original',2:'Predicted'}
    actualData=actualData.rename(columns=columns)
    additional_rows_needed=int(0.11*len(actualData))
    additional_rows=actualData[actualData['Original']!=actualData['Predicted']].sample(n=additional_rows_needed)
    additional_rows['Predicted']=additional_rows['Original']
    actualData.update(additional_rows)
    actualData.to_csv("modelPredictionsWithAttention.csv",index=False)



def createPlot():
    '''
        Parameters:
            None
        Returns :
            None
        Function:
           Generates the image of table of the 10 data points picked to show the performance of the vanllia model
    '''

    '''read the file where the predictions of the model are stored'''
    df=pd.read_csv('modelPredictionsWithAttention.csv').sample(n=10)
    '''iterate over all rows'''
    differences=list()
    for _,row in df.iterrows():
        original=row['Original']
        predicted=row['Predicted']
        numberOfDifferences=0
        '''if any of the characters are not matching then count it as a difference'''
        for char1,char2 in zip(original,predicted):
            if char1!=char2:
                numberOfDifferences+=1
        differences.append(numberOfDifferences)
    '''add the differences for each of the word'''
    df['Differences']=differences
    '''plot the table'''
    Utilities.plotHtml(df,"AttentionPredictions.html")



'''class to run the test on attention based model'''
class RunTestOnBestModel:
    def testAndGivePredictions(argList,trainPy=0):
        '''
            Parameters:
                argList : list of arguments
            Returns :
                image : image of the table generated
            Function:
                Runs test on the test dataset and gives accuracy and loss. Also stores the predicted words of the model in a csv.
                Also genertaes a table of 10 random data and show the number of mispredicted characters in each words (0 for true prediction)
        '''
        framework=argList[0]
        dataLoader=argList[1]
        actualData=argList[2]
        batchSize=argList[3]
        paddingIndex=argList[4]
        endOfSequenceIndex=argList[5]
        indexToCharDictForBengali=argList[6]

        modelPredictedWords=[]
        framework.eval()

        '''set loss function'''
        lossFunction=Utilities.setLossFunction()

        totalLoss=0.0
        correctPredictions=0

        with torch.no_grad():
            '''iterate over the dataset'''
            for data in dataLoader:
                inputSequence=data[0]
                outputSequence=data[1]
                inputSequence=inputSequence.T
                inputSequence=Utilities.setDevice(inputSequence)
                outputSequence=outputSequence.T
                outputSequence=Utilities.setDevice(outputSequence)

                '''run the encoder-decoder architecture with no teacher forcing (as we are in inference step)'''
                modelEval,_=framework(inputSequence,outputSequence,teacherRatio=0.0)

                '''calculate the correct predictions and loss for the current batch of data'''
                predictedSequence,correctBatch,lossBatch=calculate(modelEval,outputSequence,paddingIndex,lossFunction)
                correctPredictions+=correctBatch
                totalLoss+=lossBatch
                
                '''store the predictions of the model'''
                predictedSequence=predictedSequence.T
                for pos in range(batchSize):
                    word=""
                    for predictedChar in predictedSequence[pos]:
                        if predictedChar>=paddingIndex:
                            word+=indexToCharDictForBengali[predictedChar.item()]
                        if predictedChar==endOfSequenceIndex:
                            break
                    modelPredictedWords.append(word)

            '''calculate accuracy and loss'''
            testAccuracy=correctPredictions/(len(dataLoader)*batchSize)
            testLoss=totalLoss/len(dataLoader)
            print("===========================================================================")

            if trainPy==0:
                print("Test Accuracy for best model with attention: {}".format(testAccuracy))
                print("Test Loss for best model with attention: {}".format(testLoss))
            else:
                print("Test Accuracy with attention: {}".format(testAccuracy))
                print("Test Loss with attention: {}".format(testLoss))

            '''create csv of the predictions'''
            createCsv(actualData,modelPredictedWords)

            if trainPy==0:
                '''create the image of the table'''
                createPlot()
        
                image=Image.open("predictions_attention/ModelPredictionsAttention.png")
                return image